{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "outputs": [],
   "source": [
    "def rotacionar_imagem(img, angulo):\n",
    "    height = img.shape[0]  # número de linhas\n",
    "    width = img.shape[1]  # número de colunas\n",
    "\n",
    "    centroY = height / 2\n",
    "    centroX = width / 2\n",
    "\n",
    "    matrizRotacao = cv2.getRotationMatrix2D((centroX, centroY), angulo, 1.0)\n",
    "\n",
    "    img_rot = cv2.warpAffine(img, matrizRotacao, (width, height))\n",
    "\n",
    "    return img_rot\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "outputs": [],
   "source": [
    "def ransac(img1, img2, kp1, kp2, good_matches):\n",
    "    # Deve conter no caso MIN_MATCH_COUNT para considerar que encontrou a imagem\n",
    "    inliers = 0\n",
    "    outliers = 0\n",
    "    img_difference = 0\n",
    "    MIN_MATCH_COUNT = 20\n",
    "    if len(good_matches) > MIN_MATCH_COUNT:\n",
    "        # Se verdade, desenhar os inliers\n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "        # Matriz homográfica com RANSAC\n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        matchesMask = mask.ravel().tolist()  # inliers\n",
    "\n",
    "        # Calcula INLIERS e OUTLIERS\n",
    "        # mask: é um vetor que possui 0 e 1. Sendo que 1 é inlier e 0 outliers\n",
    "        for i, m in enumerate(mask):\n",
    "            if m:\n",
    "                inliers += 1\n",
    "            else:\n",
    "                outliers += 1\n",
    "\n",
    "        # Posiciona uma imagem em relação a outra\n",
    "        h, w = img1.shape\n",
    "        pts = np.float32([[0, 0], [0, h - 1], [w - 1, h - 1], [w - 1, 0]]).reshape(-1, 1, 2)\n",
    "\n",
    "        dst = cv2.perspectiveTransform(pts, M)\n",
    "        img2 = cv2.polylines(img2, [np.int32(dst)], True, 255, 3, cv2.LINE_AA)\n",
    "\n",
    "        # --- TRANSFORMAÇÃO: visando encaixar a imagem 2 na imagem 1\n",
    "        # Invertendo a transformação para subtrair da imagem original\n",
    "        M_inv = np.linalg.inv(M)  # calcula matriz inversa\n",
    "        img2_transformed = cv2.warpPerspective(img2, M_inv, (img1.shape[1], img1.shape[0]))\n",
    "        # Subtraindo a imagem transformada da imagem original\n",
    "        img_diff = cv2.absdiff(img1, img2_transformed)\n",
    "        # Exibi a imagem obtida por meio da subtração\n",
    "        img_difference = np.mean(img_diff)\n",
    "    else:\n",
    "        matchesMask = None\n",
    "\n",
    "    return inliers, outliers, img_diff, img_difference, matchesMask"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "outputs": [],
   "source": [
    "def fast_brief(query_img, train_img):\n",
    "    inicio = datetime.now()\n",
    "\n",
    "    img1 = cv2.cvtColor(query_img, cv2.COLOR_BGR2GRAY)\n",
    "    img2 = cv2.cvtColor(train_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    fast = cv2.FastFeatureDetector_create()\n",
    "\n",
    "    kp1 = fast.detect(img1, None)\n",
    "    kp2 = fast.detect(img2, None)\n",
    "\n",
    "    # Extrai os descritores usando o BRIEF\n",
    "    brief = cv2.xfeatures2d.BriefDescriptorExtractor_create()\n",
    "    kp1, des1 = brief.compute(img1, kp1)\n",
    "    kp2, des2 = brief.compute(img2, kp2)\n",
    "\n",
    "    matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = matcher.match(des1, des2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "    # Definir um limiar de distância para filtrar correspondências ruins\n",
    "    threshold_distance = 20\n",
    "\n",
    "    # Filtrar correspondências com base no limiar de distância\n",
    "    good_matches = []\n",
    "    for match in matches:\n",
    "        if match.distance < threshold_distance:\n",
    "            good_matches.append(match)\n",
    "\n",
    "    fim = datetime.now()\n",
    "\n",
    "    tempo_gasto = fim - inicio\n",
    "\n",
    "    inliers, outliers, img_diferenca, diferenca, matchesMask = ransac(img1, img2, kp1, kp2, good_matches)\n",
    "\n",
    "    # desenha os inliers\n",
    "    draw_params = dict(matchColor=(0, 255, 0),  # draw matches in green color\n",
    "                       singlePointColor=None,\n",
    "                       matchesMask=matchesMask,  # draw only inliers\n",
    "                       flags=2)\n",
    "\n",
    "    img_correspondencia = cv2.drawMatches(img1, kp1,\n",
    "                           img2, kp2, good_matches, None, **draw_params)\n",
    "\n",
    "    return inliers, outliers, diferenca, tempo_gasto, img_correspondencia, img_diferenca\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "outputs": [],
   "source": [
    "def sift_sift(query_img, train_img):\n",
    "    inicio = datetime.now()\n",
    "\n",
    "    # train_img = rotacionar_imagem(train_img,15)\n",
    "\n",
    "    # Converte para Cinza para trabalhar com um canal apenas\n",
    "    img1 = cv2.cvtColor(query_img, cv2.COLOR_BGR2GRAY)\n",
    "    img2 = cv2.cvtColor(train_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Inicializa o SIFT\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    # Extrai os pontos chaves e descritores\n",
    "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "    # --> Faz Correspondência\n",
    "    # Correspondência\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "    search_params = dict(checks=50)\n",
    "\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "    matches = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    # Armazena todas as boas correspondências de acordo com o teste de proporção de Lowe's\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.7 * n.distance:\n",
    "            good_matches.append(m)\n",
    "\n",
    "    fim = datetime.now()\n",
    "\n",
    "    tempo_gasto = fim - inicio\n",
    "\n",
    "    inliers, outliers, img_diferenca, diferenca, matchesMask = ransac(img1, img2, kp1, kp2, good_matches)\n",
    "\n",
    "    # desenha os inliers\n",
    "    draw_params = dict(matchColor=(0, 255, 0),  # draw matches in green color\n",
    "                       singlePointColor=None,\n",
    "                       matchesMask=matchesMask,  # draw only inliers\n",
    "                       flags=2)\n",
    "\n",
    "    img_correspondencia = cv2.drawMatches(img1, kp1,\n",
    "                           img2, kp2, good_matches, None, **draw_params)\n",
    "\n",
    "    return inliers, outliers, diferenca, tempo_gasto, img_correspondencia, img_diferenca"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "outputs": [],
   "source": [
    "def equaliza_cor(sat, uav):\n",
    "    # Converter ambas as imagens para o espaço de cor Lab\n",
    "    sat = cv2.cvtColor(sat, cv2.COLOR_BGR2LAB)\n",
    "    uav = cv2.cvtColor(uav, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    # Calcular a média e o desvio padrão dos canais L, a e b da imagem SAT\n",
    "    media_pixels_sat, desvio_padrao_sat = cv2.meanStdDev(sat)\n",
    "    # achatada em um array 1D, que pode ser mais facilmente manipulado\n",
    "    media_pixels_sat = media_pixels_sat.ravel()\n",
    "    desvio_padrao_sat = desvio_padrao_sat.ravel()\n",
    "\n",
    "    # Calcular a média e o desvio padrão dos canais L, a e b da imagem SAT\n",
    "    media_pixels_uav, desvio_padrao_uav = cv2.meanStdDev(sat)\n",
    "    # achatada em um array 1D, que pode ser mais facilmente manipulado\n",
    "    media_pixels_uav = media_pixels_uav.ravel()\n",
    "    desvio_padrao_uav = desvio_padrao_uav.ravel()\n",
    "\n",
    "    # Normalizar os canais da imagem UAV pela média e desvio padrão da imagem SAT\n",
    "    uav[:, :, 0] = np.clip((desvio_padrao_sat[0] / desvio_padrao_uav[0]) * (uav[:, :, 0] - media_pixels_uav[0])\n",
    "                           + media_pixels_sat[0], 0, 255)\n",
    "    uav[:, :, 1] = np.clip((desvio_padrao_sat[1] / desvio_padrao_uav[1]) * (uav[:, :, 1] - media_pixels_uav[1])\n",
    "                   + media_pixels_sat[1], 0, 255)\n",
    "    uav[:, :, 2] = np.clip((desvio_padrao_sat[2] / desvio_padrao_uav[2]) * (uav[:, :, 2] - media_pixels_uav[2])\n",
    "                   + media_pixels_sat[2], 0, 255)\n",
    "\n",
    "    # Converter de volta para o espaço de cor BGR\n",
    "    result = cv2.cvtColor(uav, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    cv2.imwrite('../../template-matching/app-correspondencia-imagem/public/images/equalize_color_img1.jpg', result)\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "outputs": [],
   "source": [
    "img_anterior = cv2.imread('./database/alvares_machado/06-22/alvares_machado_0.jpg')\n",
    "img_atual = cv2.imread('./database/alvares_machado/04-23/alvares_machado_0.jpg')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "outputs": [],
   "source": [
    "img_anterior = equaliza_cor(img_atual, img_anterior)\n",
    "# img_anterior = rotacionar_imagem(img_anterior, 45)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ---> SIFT-SIFT\n",
    "inliers, outliers, diferenca, tempo, img_correspondencia, img_diferenca = sift_sift(img_anterior, img_atual)\n",
    "# ---> FAST-BRIEF\n",
    "# inliers, outliers, diferenca, tempo, img_correspondencia, img_diferenca = fast_brief(img_anterior, img_atual)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Inliers = {inliers}\\nOutliers = {outliers}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img_correspondencia = (cv2.cvtColor(img_correspondencia, cv2.COLOR_BGR2RGB))\n",
    "plt.figure(dpi=300)\n",
    "plt.imshow(img_correspondencia)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
